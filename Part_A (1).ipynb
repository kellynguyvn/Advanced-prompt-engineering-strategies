{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ““ Google Colab: Exploring Prompt Engineering Techniques with GPT-3.5 and GPT-4\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook demonstrates various prompt engineering techniques using OpenAI's GPT-3.5 or GPT-4. We explore techniques to improve generation performance, highlight failure cases, and how each method addresses these failures. The following approaches are illustrated:\n",
        "\n",
        "- **In-Context Learning (ICL)**\n",
        "- **Chain-of-Thought (CoT)**\n",
        "- **Incremental Chain-of-Thought (iCOT)**\n",
        "- **Tree-of-Thought (ToT)**\n",
        "- **Graph-of-Thought (GoT)**\n",
        "- **Agent-of-Thought (AoT)**\n",
        "- **Reasoning with Self-Consistency and Error Feedback (RASCEF)**\n",
        "- **Reasoning and Action Chain Extraction (REACT)**"
      ],
      "metadata": {
        "id": "QVUXLe0pVv6m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePrHF51gDYC6",
        "outputId": "007d925c-4ef2-4ed9-99a9-7a9e23dcfcb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "## Setup\n",
        "!pip install openai==0.28\n",
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = \"OPENAI_API_KEY\"\n",
        "\n",
        "def get_response(system_prompt, user_message, model=\"gpt-4\"):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "# Function to call the OpenAI API for simple prompts (like before)\n",
        "def get_icl_response(icl_prompt, model=\"gpt-4\"):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": icl_prompt}\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "icl_prompt = \"\"\"\n",
        "Example 1: If Alice has 2 apples and Bob gives her 3 more apples, how many apples does Alice have?\n",
        "Answer: 5\n",
        "\n",
        "Example 2: If John has 5 bananas and gives 2 bananas to Sarah, how many bananas does John have left?\n",
        "Answer: 3\n",
        "\n",
        "Example 3: If Jane has 7 oranges and gives 4 to Emily, how many oranges does Jane have?\n",
        "Answer:\n",
        "\"\"\"\n",
        "print(\"ICL Response:\\n\", get_icl_response(icl_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zulbapm7VzQe",
        "outputId": "3bed7d53-d466-4332-996e-be9646a9dd1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ICL Response:\n",
            " 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Failure Case**\n",
        "<br>\n",
        "ICL often fails when there's insufficient data in the context or if the examples are ambiguous."
      ],
      "metadata": {
        "id": "A_s1verRV2YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "icl_failure_prompt = \"Alice has an unknown number of apples, and Bob gives her some more. How many apples does Alice have now?\"\n",
        "print(\"ICL Failure Response:\\n\", get_icl_response(icl_failure_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B50T5bSV582",
        "outputId": "3357dfb2-641d-4b61-f24c-8df6db8718b5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ICL Failure Response:\n",
            " Without specific information on the number of apples Alice initially had and the number she received from Bob, it's impossible to determine the exact number of apples Alice has now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain-of-Thought (CoT)\n",
        "**Example**\n",
        "CoT encourages the model to generate intermediate reasoning steps to solve a problem."
      ],
      "metadata": {
        "id": "UVkc7iv2V9pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_prompt = \"\"\"\n",
        "If Jack has 10 chocolates and eats 3 chocolates per day for 2 days, how many chocolates are left?\n",
        "\n",
        "Step 1: Jack eats 3 chocolates per day.\n",
        "Step 2: Jack eats 3 * 2 = 6 chocolates in 2 days.\n",
        "Step 3: Initially, Jack has 10 chocolates.\n",
        "Step 4: After eating 6 chocolates, Jack is left with 10 - 6 = 4 chocolates.\n",
        "Answer: 4\n",
        "\"\"\"\n",
        "\n",
        "# Get response using ChatCompletion for CoT example\n",
        "cot_response = get_icl_response(cot_prompt)\n",
        "print(\"CoT Response:\\n\", cot_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTAX9rX1WCqo",
        "outputId": "c28ff388-25ca-406b-f10d-a42c173acb61"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CoT Response:\n",
            " Jack has 4 chocolates left.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Failure Case** <br>\n",
        "When steps are missing, the model can reach incorrect conclusions."
      ],
      "metadata": {
        "id": "LmzqCmmLWGCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cot_failure_prompt = \"\"\"\n",
        "If Tom has 15 apples and eats 4 per day for 3 days, how many apples are left?\n",
        "Answer without steps:\n",
        "\"\"\"\n",
        "print(\"CoT Failure Response:\\n\", get_icl_response(cot_failure_prompt))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr7NypCkWDLd",
        "outputId": "9b58e2f5-843a-41c9-bc6b-cabf8987eea9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CoT Failure Response:\n",
            " 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Incremental Chain-of-Thought (iCOT)\n",
        "Example\n",
        "iCOT gradually reveals steps, which can lead to better logical consistency."
      ],
      "metadata": {
        "id": "ZGZInfilWJ1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "icot_prompt = \"\"\"\n",
        "Question: If Sarah has 18 candies and she gives 5 candies to her friend every day for 3 days, how many candies does she have left?\n",
        "\n",
        "Step 1: How many candies does Sarah give in one day?\n",
        "Answer: 5 candies.\n",
        "\n",
        "Step 2: How many days does she give candies?\n",
        "Answer: 3 days.\n",
        "\n",
        "Step 3: Total candies given = 5 * 3 = 15.\n",
        "Step 4: Remaining candies = 18 - 15 = 3.\n",
        "Answer: 3\n",
        "\"\"\"\n",
        "print(\"iCOT Response:\\n\", get_icl_response(icot_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haxLH9gEWMh5",
        "outputId": "fad7a164-6954-43bb-e595-8015fd3f2428"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iCOT Response:\n",
            " Sarah has 3 candies left.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tree-of-Thought (ToT)\n",
        "ToT helps handle complex questions by considering multiple branches of reasoning."
      ],
      "metadata": {
        "id": "TU-VXiC-WLmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tot_prompt = \"\"\"\n",
        "Is it better to invest in stocks or bonds?\n",
        "1. Consider risk levels:\n",
        "    - Stocks: High risk, potentially high reward.\n",
        "    - Bonds: Lower risk, stable returns.\n",
        "\n",
        "2. Consider time horizon:\n",
        "    - Long-term: Stocks may outperform.\n",
        "    - Short-term: Bonds are safer.\n",
        "\n",
        "Conclusion depends on risk appetite and time horizon.\n",
        "\"\"\"\n",
        "print(\"ToT Response:\\n\", get_icl_response(tot_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poD0JLTTWTVj",
        "outputId": "224ce714-91dd-4017-93ca-dee053f5e61c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ToT Response:\n",
            " 3. Consider economic conditions:\n",
            "    - In a growing economy, stocks often perform better.\n",
            "    - In a stagnant or declining economy, bonds may be safer.\n",
            "\n",
            "4. Consider tax implications:\n",
            "    - Some bonds, like municipal bonds, may be exempt from certain taxes.\n",
            "    - Stocks may be subject to capital gains tax.\n",
            "\n",
            "5. Consider diversification:\n",
            "    - Holding a mix of both stocks and bonds can provide balance in your portfolio.\n",
            "\n",
            "Ultimately, the decision to invest in stocks or bonds depends on your individual financial goals, risk tolerance, and investment strategy. It's often recommended to have a diversified portfolio that includes both stocks and bonds. It's also a good idea to consult with a financial advisor or do thorough research before making investment decisions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph-of-Thought (GoT)\n",
        "Graph-of-Thought helps with complex relationships, often helpful in causal reasoning."
      ],
      "metadata": {
        "id": "3kXYxgwWWVwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "got_prompt = \"\"\"\n",
        "A -> B: Exercising improves health.\n",
        "B -> C: Improved health leads to better mood.\n",
        "D: Lack of sleep negatively affects mood.\n",
        "If A and D happen, what is the effect on C?\n",
        "\"\"\"\n",
        "print(\"GoT Response:\\n\", get_icl_response(got_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7GVdnbXWVjw",
        "outputId": "85c34884-85eb-47a9-d501-0c52f794b53b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GoT Response:\n",
            " The effect on C would be mixed. On one hand, exercising (A) would improve health (B) leading to a better mood (C). On the other hand, lack of sleep (D) would negatively affect the mood (C). So, the overall outcome would depend on the intensity and balance of these two effects.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent-of-Thought (AoT)\n",
        "Agents act as individual thinking entities providing input, enabling emergent reasoning."
      ],
      "metadata": {
        "id": "p0-ixcN_WZOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aot_prompt = \"\"\"\n",
        "Agent 1: I think the answer is 10 based on my calculations.\n",
        "Agent 2: I disagree. I think the answer should be recalculated considering extra factors.\n",
        "Agent 3: Considering both, the adjusted answer might be 8.\n",
        "Answer: 8\n",
        "\"\"\"\n",
        "print(\"AoT Response:\\n\", get_icl_response(aot_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-zjWRIHWa2l",
        "outputId": "61880c21-457d-436c-faa0-7058d71581e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AoT Response:\n",
            " Agent 1: That's interesting. I must have missed those factors. Can you clarify what they are?\n",
            "Agent 2: Sure, the factors are X and Y, which have a significant impact on the result.\n",
            "Agent 3: Correct, taking those into account changes the outcome.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reasoning with Self-Consistency and Error Feedback (RASCEF)\n",
        "RASCEF allows multiple attempts, aiming for consistent answers by correcting errors."
      ],
      "metadata": {
        "id": "kPiBPqG0Wg_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rascef_prompt = \"\"\"\n",
        "If Tim has 25 dollars and spends 7 dollars each day, how many days can he spend before running out?\n",
        "\n",
        "Attempt 1:\n",
        "Day 1: 25 - 7 = 18.\n",
        "Day 2: 18 - 7 = 11.\n",
        "Day 3: 11 - 7 = 4.\n",
        "Day 4: Not enough for a full 7.\n",
        "\n",
        "Correct Answer: 3 full days.\n",
        "\"\"\"\n",
        "print(\"RASCEF Response:\\n\", get_icl_response(rascef_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAJmwit9WjBh",
        "outputId": "0c0cb78b-106c-429c-a9e8-6457b67ad127"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RASCEF Response:\n",
            " Alternatively, you can divide the total amount of money Tim has by the amount he spends each day. \n",
            "\n",
            "25 / 7 = 3.57 \n",
            "\n",
            "Since Tim cannot spend partial days, he can only spend for 3 full days.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reasoning and Action Chain Extraction (REACT)\n",
        "REACT is useful when reasoning also involves taking actions."
      ],
      "metadata": {
        "id": "jeW_HTq-WlS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "react_prompt = \"\"\"\n",
        "User: Book a taxi to the airport.\n",
        "\n",
        "Reasoning:\n",
        "1. Find the userâ€™s location.\n",
        "2. Use a ride-hailing service.\n",
        "3. Confirm time and location.\n",
        "\n",
        "Action:\n",
        "Booking a taxi for the requested time.\n",
        "\"\"\"\n",
        "print(\"REACT Response:\\n\", get_icl_response(react_prompt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZb-vDCnWk_B",
        "outputId": "fe40ab92-72a7-43fd-c94a-f8f6e1698646"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REACT Response:\n",
            " Assistant: Sure, I can help you with that. Can you please let me know the following details:\n",
            "1. Your current location or pickup point.\n",
            "2. The specific airport you are traveling to.\n",
            "3. The date and time you would like the taxi to pick you up.\n",
            "Once I have these details, I will be able to book the taxi for you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "This notebook shows how prompt engineering techniques can make a difference in the responses from GPT models. Each technique has strengths and weaknesses, and understanding these helps in applying the correct approach for different types of problems."
      ],
      "metadata": {
        "id": "NSAvyLm1Wq5M"
      }
    }
  ]
}